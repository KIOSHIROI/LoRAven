# GLUEå®Œæ•´å®éªŒè¿è¡Œè„šæœ¬
# è¯¥è„šæœ¬æ‰§è¡ŒLoRAã€AdaLoRAã€DoRAåœ¨GLUEä»»åŠ¡ä¸Šçš„å®Œæ•´å¯¹æ¯”å®éªŒ
# æµ‹è¯•åŠŸèƒ½ï¼š
# 1. åœ¨SST-2ã€MNLIã€QNLIã€RTEã€CoLAäº”ä¸ªä»»åŠ¡ä¸Šè¿è¡Œå®éªŒ
# 2. å¯¹æ¯”LoRAã€AdaLoRAã€DoRAä¸‰ç§PEFTæ–¹æ³•çš„æ€§èƒ½
# 3. æ”¶é›†å¹¶ä¿å­˜æ‰€æœ‰å®éªŒç»“æœ
# 4. ç”Ÿæˆæ€§èƒ½å¯¹æ¯”æŠ¥å‘Š

import os
import sys
import json
import time
from pathlib import Path

# æ·»åŠ å®éªŒç›®å½•åˆ°è·¯å¾„
sys.path.append('experiments')
from glue_benchmark import GLUEBenchmark, ExperimentConfig

def main():
    """è¿è¡Œå®Œæ•´çš„GLUEåŸºå‡†æµ‹è¯•å®éªŒ"""
    
    # è®¾ç½®Hugging Faceé•œåƒ
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    
    # è®¾ç½®tokenizerså¹¶è¡ŒåŒ–ï¼Œé¿å…forkè­¦å‘Š
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    
    # è®¾ç½®Hugging Faceç¼“å­˜ç›®å½•åˆ°é¡¹ç›®æœ¬åœ°
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    hf_cache_dir = os.path.join(project_root, ".hf_cache")
    
    # åˆ›å»ºç¼“å­˜ç›®å½•
    os.makedirs(hf_cache_dir, exist_ok=True)
    os.makedirs(os.path.join(hf_cache_dir, "transformers"), exist_ok=True)
    os.makedirs(os.path.join(hf_cache_dir, "datasets"), exist_ok=True)
    os.makedirs(os.path.join(hf_cache_dir, "hub"), exist_ok=True)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["HF_HOME"] = hf_cache_dir
    os.environ["TRANSFORMERS_CACHE"] = os.path.join(hf_cache_dir, "transformers")
    os.environ["HF_DATASETS_CACHE"] = os.path.join(hf_cache_dir, "datasets")
    os.environ["HUGGINGFACE_HUB_CACHE"] = os.path.join(hf_cache_dir, "hub")
    
    # å®éªŒé…ç½®
    config = ExperimentConfig(
        model_name='bert-base-uncased',
        tasks=['sst2', 'mnli', 'qnli', 'rte', 'cola'],
        max_length=128,
        batch_size=100,  # å‡å°æ‰¹æ¬¡å¤§å°ä»¥èŠ‚çœGPUå†…å­˜
        num_epochs=1,   # å®Œæ•´è®­ç»ƒ3ä¸ªepoch
        learning_rate=2e-5,
        warmup_steps=500,
        output_dir='./full_experiment_results',
        use_mixed_precision=True,  # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        dataloader_num_workers=8   # å¢åŠ æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹
    )
    
    # PEFTæ–¹æ³•åˆ—è¡¨
    methods = ['lora', 'adalora', 'dora']
    
    # åˆ›å»ºåŸºå‡†æµ‹è¯•å®ä¾‹
    benchmark = GLUEBenchmark(config)
    
    print("ğŸš€ å¼€å§‹GLUEå®Œæ•´åŸºå‡†æµ‹è¯•å®éªŒ...")
    print(f"ä»»åŠ¡: {config.tasks}")
    print(f"æ–¹æ³•: {methods}")
    print(f"ä½¿ç”¨è®¾å¤‡: CUDA:0, CUDA:1, CUDA:2 ,CUDA:3 (å¤šGPUå¹¶è¡Œè®­ç»ƒ)")
    print(f"æ‰¹æ¬¡å¤§å°: {config.batch_size} (æ¯GPU)")
    print(f"æ··åˆç²¾åº¦è®­ç»ƒ: {'å¯ç”¨' if config.use_mixed_precision else 'ç¦ç”¨'}")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰å®éªŒ
    start_time = time.time()
    
    try:
        results = benchmark.run_all_experiments(methods)
        
        # ä¿å­˜ç»“æœ
        results_file = Path(config.output_dir) / "complete_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆæŠ¥å‘Š
        benchmark.generate_comparison_report(results)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print("\n" + "=" * 60)
        print("âœ… å®éªŒå®Œæˆ!")
        print(f"æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")
        print(f"ç»“æœä¿å­˜åœ¨: {results_file}")
        print("è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ")
        
    except Exception as e:
        print(f"âŒ å®éªŒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()