#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°å­¦å…¬å¼å•å…ƒæµ‹è¯•
ç¡®ä¿LoRAvenä¸­æ‰€æœ‰æ•°å­¦å…¬å¼çš„å®ç°æ­£ç¡®æ€§
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import torch
import torch.nn as nn
import pytest
import numpy as np
from typing import Dict, List, Tuple, Optional
import traceback

# å¯¼å…¥LoRAvenç»„ä»¶
from loraven.loraven.core.models.dynamic_lowrank_layer import DynamicLowRankLayer
from loraven.loraven.core.models.gates import LightweightScorer, GateNetwork
from loraven.loraven.core.rank_scheduler import RankScheduler, LinearRankScheduler, EnergyAwareRankScheduler
from loraven.loraven.core.budget_manager import BudgetManager
from loraven.loraven.utils.perf_estimator import PerfEstimator, EnergyEstimator
from loraven.loraven.loraven_simple import LoRAven


class TestLowRankDecomposition:
    """æµ‹è¯•ä½ç§©åˆ†è§£å…¬å¼ W â‰ˆ U Î£ V^T"""
    
    def test_lowrank_decomposition_basic(self):
        """åŸºç¡€ä½ç§©åˆ†è§£æµ‹è¯•"""
        layer = DynamicLowRankLayer(
            in_features=64,
            out_features=32,
            r_max=16,
            r_min=4
        )
        
        x = torch.randn(8, 64)
        output, current_rank = layer(x)
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        assert output.shape == (8, 32), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {output.shape}"
        assert 4 <= current_rank <= 16, f"ç§©è¶…å‡ºèŒƒå›´: {current_rank}"
    
    def test_lowrank_mathematical_consistency(self):
        """éªŒè¯ä½ç§©åˆ†è§£çš„æ•°å­¦ä¸€è‡´æ€§"""
        layer = DynamicLowRankLayer(
            in_features=32,
            out_features=16,
            r_max=8,
            r_min=2
        )
        
        x = torch.randn(4, 32)
        output, current_rank = layer(x)
        
        # è·å–å› å­çŸ©é˜µ
        U = layer.U_full[:, :current_rank]
        V = layer.V_full[:, :current_rank]
        S = layer.S_full[:current_rank, :current_rank]
        
        # é‡æ„æƒé‡çŸ©é˜µ W â‰ˆ U @ S @ V^T
        W_reconstructed = U @ S @ V.T
        
        # éªŒè¯çŸ©é˜µä¹˜æ³•: y = x @ W^T â‰ˆ x @ V @ S @ U^T
        y_direct = x @ W_reconstructed.T
        y_factorized = x @ V @ S @ U.T
        
        # è®¡ç®—è¯¯å·®
        error = torch.norm(y_direct - y_factorized).item()
        assert error < 1e-4, f"åˆ†è§£è¯¯å·®è¿‡å¤§: {error}"


class TestComplexityScoring:
    """æµ‹è¯•å¤æ‚åº¦è¯„åˆ†å…¬å¼ s(x) = Ïƒ(f_Î¸(x))"""
    
    def test_complexity_scoring_range(self):
        """æµ‹è¯•å¤æ‚åº¦åˆ†æ•°èŒƒå›´"""
        scorer = LightweightScorer(in_features=64, hidden_dim=32)
        x = torch.randn(8, 64)
        
        scores = scorer(x)
        
        # éªŒè¯è¾“å‡ºåœ¨[0,1]èŒƒå›´å†…
        assert torch.all(scores >= 0), "å¤æ‚åº¦åˆ†æ•°å­˜åœ¨è´Ÿå€¼"
        assert torch.all(scores <= 1), "å¤æ‚åº¦åˆ†æ•°è¶…è¿‡1"
        # ä¿®æ­£å½¢çŠ¶æ£€æŸ¥ - LightweightScorerè¿”å›(batch_size, 1)
        assert scores.shape == (8, 1), f"åˆ†æ•°å½¢çŠ¶é”™è¯¯: {scores.shape}"
    
    def test_complexity_scoring_consistency(self):
        """æµ‹è¯•å¤æ‚åº¦è¯„åˆ†çš„ä¸€è‡´æ€§"""
        scorer = LightweightScorer(in_features=32, hidden_dim=16)
        scorer.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œé¿å…dropoutç­‰éšæœºæ€§
        
        # ç›¸åŒè¾“å…¥åº”äº§ç”Ÿç›¸åŒåˆ†æ•°
        x = torch.randn(4, 32)
        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
            scores1 = scorer(x)
            scores2 = scorer(x)
        
        assert torch.allclose(scores1, scores2, atol=1e-6), "ç›¸åŒè¾“å…¥äº§ç”Ÿä¸åŒåˆ†æ•°"


class TestRankScheduling:
    """æµ‹è¯•ç§©è°ƒåº¦å…¬å¼"""
    
    def test_linear_rank_scheduling(self):
        """æµ‹è¯•çº¿æ€§ç§©è°ƒåº¦"""
        scheduler = LinearRankScheduler(r_min=4, r_max=64)
        
        # æµ‹è¯•ä¸åŒå¤æ‚åº¦åˆ†æ•°
        low_complexity = torch.tensor([0.2, 0.2, 0.2])
        high_complexity = torch.tensor([0.8, 0.8, 0.8])
        
        rank_low = scheduler.schedule_rank(low_complexity)
        rank_high = scheduler.schedule_rank(high_complexity)
        
        assert 4 <= rank_low <= 64, f"ä½å¤æ‚åº¦ç§©è¶…å‡ºèŒƒå›´: {rank_low}"
        assert 4 <= rank_high <= 64, f"é«˜å¤æ‚åº¦ç§©è¶…å‡ºèŒƒå›´: {rank_high}"
        assert rank_low < rank_high, "é«˜å¤æ‚åº¦åº”åˆ†é…æ›´é«˜çš„ç§©"
    
    def test_energy_aware_scheduling(self):
        """æµ‹è¯•èƒ½è€—æ„ŸçŸ¥ç§©è°ƒåº¦"""
        scheduler = EnergyAwareRankScheduler(
            r_min=4, 
            r_max=64,
            energy_model=None  # ä½¿ç”¨å†…ç½®ç®€åŒ–æ¨¡å‹
        )
        
        complexity_scores = torch.tensor([0.5, 0.5, 0.5])
        
        # ä¸åŒé¢„ç®—åº”äº§ç”Ÿä¸åŒç§©
        rank_low_budget = scheduler.schedule_rank(
            complexity_scores, 
            budget=5.0,
            layer_dims=(512, 256)
        )
        
        rank_high_budget = scheduler.schedule_rank(
            complexity_scores, 
            budget=20.0,
            layer_dims=(512, 256)
        )
        
        assert 4 <= rank_low_budget <= 64, f"ä½é¢„ç®—ç§©è¶…å‡ºèŒƒå›´: {rank_low_budget}"
        assert 4 <= rank_high_budget <= 64, f"é«˜é¢„ç®—ç§©è¶…å‡ºèŒƒå›´: {rank_high_budget}"
        assert rank_low_budget <= rank_high_budget, "é«˜é¢„ç®—åº”å…è®¸æ›´é«˜çš„ç§©"


class TestEnergyEstimation:
    """æµ‹è¯•èƒ½è€—ä¼°ç®—å…¬å¼"""
    
    def test_energy_estimation_monotonicity(self):
        """æµ‹è¯•èƒ½è€—ä¼°ç®—çš„å•è°ƒæ€§"""
        hardware_profile = {
            'dram_energy_per_byte': 1e-6,
            'l2_cache_energy_per_byte': 1e-7,
            'l1_cache_energy_per_byte': 1e-8,
            'gpu_cores': 5120,
            'base_frequency': 1.5e9
        }
        estimator = EnergyEstimator(hardware_profile)
        
        layer_dims = (64, 32)
        batch_size = 8
        
        # æµ‹è¯•èƒ½è€—éšç§©å¢åŠ è€Œå¢åŠ 
        ranks = [4, 8, 16, 32]
        energies = [estimator.estimate(layer_dims, r, batch_size) for r in ranks]
        
        for i in range(len(energies) - 1):
            assert energies[i] <= energies[i + 1], f"èƒ½è€—ä¸æ»¡è¶³å•è°ƒæ€§: {energies}"
    
    def test_energy_estimation_values(self):
        """æµ‹è¯•èƒ½è€—ä¼°ç®—å€¼çš„åˆç†æ€§"""
        hardware_profile = {
            'dram_energy_per_byte': 1e-6,
            'l2_cache_energy_per_byte': 1e-7,
            'l1_cache_energy_per_byte': 1e-8,
            'gpu_cores': 5120,
            'base_frequency': 1.5e9
        }
        estimator = EnergyEstimator(hardware_profile)
        
        energy = estimator.estimate((64, 32), 8, 4)
        
        assert energy > 0, "èƒ½è€—åº”ä¸ºæ­£å€¼"
        assert energy < 1000, f"èƒ½è€—å€¼è¿‡å¤§: {energy} mJ"


class TestLossFunction:
    """æµ‹è¯•æŸå¤±å‡½æ•°ç»„åˆ"""
    
    def test_loss_combination_formula(self):
        """æµ‹è¯•æŸå¤±å‡½æ•°ç»„åˆå…¬å¼ L = L_task + Î»_E * L_energy + Î»_R * L_rank"""
        # æ¨¡æ‹ŸæŸå¤±ç»„ä»¶
        task_loss = torch.tensor(2.5)
        energy_penalty = torch.tensor(0.3)
        rank_penalty = torch.tensor(0.1)
        
        # æƒé‡å‚æ•°
        lambda_energy = 0.1
        lambda_rank = 0.05
        
        # è®¡ç®—æ€»æŸå¤±
        total_loss = task_loss + lambda_energy * energy_penalty + lambda_rank * rank_penalty
        
        # éªŒè¯æ•°å­¦æ­£ç¡®æ€§
        expected_total = 2.5 + 0.1 * 0.3 + 0.05 * 0.1
        
        assert abs(total_loss.item() - expected_total) < 1e-6, "æŸå¤±å‡½æ•°ç»„åˆè®¡ç®—é”™è¯¯"
    
    def test_loss_components_positive(self):
        """æµ‹è¯•æŸå¤±ç»„ä»¶çš„æ­£å€¼æ€§"""
        task_loss = torch.tensor(1.0)
        energy_penalty = torch.tensor(0.2)
        rank_penalty = torch.tensor(0.05)
        
        assert task_loss >= 0, "ä»»åŠ¡æŸå¤±åº”ä¸ºéè´Ÿå€¼"
        assert energy_penalty >= 0, "èƒ½è€—æƒ©ç½šåº”ä¸ºéè´Ÿå€¼"
        assert rank_penalty >= 0, "ç§©æƒ©ç½šåº”ä¸ºéè´Ÿå€¼"


class TestIntegration:
    """é›†æˆæµ‹è¯•ï¼šéªŒè¯å„ç»„ä»¶ååŒå·¥ä½œ"""
    
    def test_full_pipeline(self):
        """æµ‹è¯•å®Œæ•´çš„å‰å‘ä¼ æ’­æµæ°´çº¿"""
        # åˆ›å»ºç»„ä»¶
        layer = DynamicLowRankLayer(
            in_features=32,
            out_features=16,
            r_max=8,
            r_min=2
        )
        
        # åˆ›å»ºè¾“å…¥
        x = torch.randn(4, 32)
        
        # å‰å‘ä¼ æ’­
        output, current_rank = layer(x)
        
        # éªŒè¯è¾“å‡º
        assert output.shape == (4, 16), "è¾“å‡ºå½¢çŠ¶é”™è¯¯"
        assert 2 <= current_rank <= 8, "ç§©è¶…å‡ºèŒƒå›´"
        assert not torch.isnan(output).any(), "è¾“å‡ºåŒ…å«NaNå€¼"
        assert not torch.isinf(output).any(), "è¾“å‡ºåŒ…å«æ— ç©·å€¼"


def run_test_class(test_class, class_name):
    """è¿è¡Œæµ‹è¯•ç±»ä¸­çš„æ‰€æœ‰æµ‹è¯•æ–¹æ³•"""
    print(f"\n=== è¿è¡Œ {class_name} ===")
    
    instance = test_class()
    test_methods = [method for method in dir(instance) if method.startswith('test_')]
    
    passed = 0
    total = len(test_methods)
    
    for method_name in test_methods:
        try:
            method = getattr(instance, method_name)
            method()
            print(f"âœ“ {method_name}")
            passed += 1
        except Exception as e:
            print(f"âœ— {method_name}: {str(e)}")
            traceback.print_exc()
    
    print(f"{class_name}: {passed}/{total} æµ‹è¯•é€šè¿‡")
    return passed, total


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    print("LoRAven æ•°å­¦å…¬å¼å•å…ƒæµ‹è¯•")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•ç±»
    test_classes = [
        (TestLowRankDecomposition, "ä½ç§©åˆ†è§£æµ‹è¯•"),
        (TestComplexityScoring, "å¤æ‚åº¦è¯„åˆ†æµ‹è¯•"),
        (TestRankScheduling, "ç§©è°ƒåº¦æµ‹è¯•"),
        (TestEnergyEstimation, "èƒ½è€—ä¼°ç®—æµ‹è¯•"),
        (TestLossFunction, "æŸå¤±å‡½æ•°æµ‹è¯•"),
        (TestIntegration, "é›†æˆæµ‹è¯•")
    ]
    
    total_passed = 0
    total_tests = 0
    
    for test_class, class_name in test_classes:
        try:
            passed, tests = run_test_class(test_class, class_name)
            total_passed += passed
            total_tests += tests
        except Exception as e:
            print(f"âœ— {class_name} è¿è¡Œå¤±è´¥: {str(e)}")
            traceback.print_exc()
    
    print("\n" + "=" * 60)
    print(f"æ€»ä½“ç»“æœ: {total_passed}/{total_tests} æµ‹è¯•é€šè¿‡")
    
    if total_passed == total_tests:
        print("ğŸ‰ æ‰€æœ‰æ•°å­¦å…¬å¼æµ‹è¯•é€šè¿‡ï¼")
        sys.exit(0)
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        sys.exit(1)